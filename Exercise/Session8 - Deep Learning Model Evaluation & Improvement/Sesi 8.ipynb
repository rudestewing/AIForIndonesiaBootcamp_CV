{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Obtaining dependency information for bayesian-optimization from https://files.pythonhosted.org/packages/45/cf/3016b660afca02c6ecca3c1cc6d8df3b8f1a6ff4878103204d0aa6b4c769/bayesian_optimization-1.4.3-py3-none-any.whl.metadata\n",
      "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl.metadata (543 bytes)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/rudisetiawan/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from bayesian-optimization) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/rudisetiawan/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from bayesian-optimization) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/rudisetiawan/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from bayesian-optimization) (1.4.0)\n",
      "Collecting colorama>=0.4.6 (from bayesian-optimization)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/rudisetiawan/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rudisetiawan/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n",
      "Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: colorama, bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "def create_model(learning_rate, num_hidden_layers, num_neurons):\n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(num_neurons, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function to optimize\n",
    "def objective(learning_rate, num_hidden_layers, num_neurons):\n",
    "    model = create_model(learning_rate, int(num_hidden_layers), int(num_neurons))\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=0)\n",
    "    val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "pbounds = {'learning_rate': (0.0001, 0.1),\n",
    "           'num_hidden_layers': (1, 5),\n",
    "           'num_neurons': (5, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | num_hi... | num_ne... |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.02827  \u001b[0m | \u001b[0m3.701    \u001b[0m | \u001b[0m5.902    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9737   \u001b[0m | \u001b[0m0.01993  \u001b[0m | \u001b[0m2.245    \u001b[0m | \u001b[0m49.51    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9649   \u001b[0m | \u001b[0m0.04697  \u001b[0m | \u001b[0m3.499    \u001b[0m | \u001b[0m43.64    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9737   \u001b[0m | \u001b[0m0.09998  \u001b[0m | \u001b[0m1.498    \u001b[0m | \u001b[0m5.499    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9649   \u001b[0m | \u001b[0m0.09242  \u001b[0m | \u001b[0m3.4      \u001b[0m | \u001b[0m41.76    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.7105   \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m7.881    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.05389  \u001b[0m | \u001b[0m2.913    \u001b[0m | \u001b[0m5.755    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m2.283    \u001b[0m | \u001b[0m46.71    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m4.668    \u001b[0m | \u001b[0m47.81    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9123   \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m44.51    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.01586  \u001b[0m | \u001b[0m4.949    \u001b[0m | \u001b[0m45.47    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.9386   \u001b[0m | \u001b[0m0.08188  \u001b[0m | \u001b[0m4.933    \u001b[0m | \u001b[0m39.03    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.7105   \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m48.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m0.0671   \u001b[0m | \u001b[0m3.436    \u001b[0m | \u001b[0m46.31    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.9649   \u001b[0m | \u001b[0m0.08078  \u001b[0m | \u001b[0m4.972    \u001b[0m | \u001b[0m44.17    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.9737   \u001b[0m | \u001b[0m0.08027  \u001b[0m | \u001b[0m3.594    \u001b[0m | \u001b[0m49.8     \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.5702   \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m1.752    \u001b[0m | \u001b[0m7.047    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.04176  \u001b[0m | \u001b[0m4.01     \u001b[0m | \u001b[0m44.88    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.9649   \u001b[0m | \u001b[0m0.005503 \u001b[0m | \u001b[0m3.318    \u001b[0m | \u001b[0m48.4     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.08016  \u001b[0m | \u001b[0m3.464    \u001b[0m | \u001b[0m5.001    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.9386   \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m42.13    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.9649   \u001b[0m | \u001b[0m0.008999 \u001b[0m | \u001b[0m2.598    \u001b[0m | \u001b[0m39.98    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.02938  \u001b[0m | \u001b[0m1.543    \u001b[0m | \u001b[0m41.6     \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.9737   \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m40.03    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.9737   \u001b[0m | \u001b[0m0.07442  \u001b[0m | \u001b[0m1.566    \u001b[0m | \u001b[0m38.16    \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform Bayesian optimization\n",
    "optimizer = BayesianOptimization(f=objective, pbounds=pbounds, verbose=2)\n",
    "optimizer.maximize(init_points=5, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized hyperparameters:\n",
      "{'learning_rate': 0.028271576923410802, 'num_hidden_layers': 3.700612849088747, 'num_neurons': 5.901978061489136}\n",
      "Validation accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "# Print the optimized hyperparameters and validation accuracy\n",
    "print('Optimized hyperparameters:')\n",
    "print(optimizer.max['params'])\n",
    "print('Validation accuracy: {:.2f}%'.format(optimizer.max['target'] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0051305819c00f3c67001f9fdd376c54aa8e69e0ddd05df36d593c70cd82294"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
